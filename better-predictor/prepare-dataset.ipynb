{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "DESIRED_REGION_SIZE_KM: np.float64 = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get domain bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from dataset_objects.bbox import BoundingBox\n",
    "from remote.remote import Remote\n",
    "\n",
    "whole_region_bbox: BoundingBox = Remote.get_bounding_box()\n",
    "whole_region_bbox.summary()\n",
    "\n",
    "plt.scatter(\n",
    "    [whole_region_bbox.north_east.longitude, whole_region_bbox.north_west.longitude, whole_region_bbox.south_east.longitude, whole_region_bbox.south_west.longitude],\n",
    "    [whole_region_bbox.north_east.latitude, whole_region_bbox.north_west.latitude, whole_region_bbox.south_east.latitude, whole_region_bbox.south_west.latitude]\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate south-west points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_height:int = round(whole_region_bbox.height / DESIRED_REGION_SIZE_KM)\n",
    "cells_width:int = round(whole_region_bbox.width / DESIRED_REGION_SIZE_KM)\n",
    "\n",
    "print(f'Matrix will be {cells_height} cells high and {cells_width} cells wide.')\n",
    "bases_x = [((x / cells_width) * (whole_region_bbox.south_east.longitude - whole_region_bbox.south_west.longitude)) + whole_region_bbox.south_west.longitude\n",
    "              for x in range(cells_width) for y in range(cells_height)]\n",
    "bases_y = [((y / cells_height) * (whole_region_bbox.north_west.latitude - whole_region_bbox.south_west.latitude)) + whole_region_bbox.south_west.latitude\n",
    "              for x in range(cells_width) for y in range(cells_height)]\n",
    "plt.scatter(\n",
    "    bases_x,\n",
    "    bases_y\n",
    ")\n",
    "plt.title(\"South east coordinate of each cell\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bounds based on south-west points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset_objects.coordinates import Coordinates\n",
    "\n",
    "difference_in_latitude = bases_y[1] - bases_y[0]\n",
    "difference_in_longitude = bases_x[cells_height + 1] - bases_x[0]\n",
    "print(f'Difference in latitude is {difference_in_latitude:.8f}')\n",
    "print(f'Difference in longitude is {difference_in_longitude:.8f}')\n",
    "cells = [\n",
    "    [ \n",
    "        BoundingBox(\n",
    "            south_west = Coordinates(\n",
    "                latitude=(y * difference_in_latitude) + whole_region_bbox.south_west.latitude,\n",
    "                longitude=(x * difference_in_longitude) + whole_region_bbox.south_west.longitude\n",
    "            ),\n",
    "            north_east = Coordinates(\n",
    "                latitude=((y + 1) * difference_in_latitude) + whole_region_bbox.south_west.latitude,\n",
    "                longitude=((x + 1) * difference_in_longitude) + whole_region_bbox.south_west.longitude\n",
    "            ),\n",
    "            x = x,\n",
    "            y = y\n",
    "        ) for y in range(cells_height)\n",
    "    ] for x in range(cells_width)\n",
    "]\n",
    "\n",
    "bounds_x = []\n",
    "bounds_y = []\n",
    "for x in range(cells_width):\n",
    "    for y in range(cells_height):\n",
    "        cell = cells[x][y]\n",
    "        bounds_x.append(cell.north_east.longitude)\n",
    "        bounds_x.append(cell.south_east.longitude)\n",
    "        bounds_x.append(cell.south_west.longitude)\n",
    "        bounds_x.append(cell.north_west.longitude)\n",
    "\n",
    "        bounds_y.append(cell.north_east.latitude)\n",
    "        bounds_y.append(cell.south_east.latitude)\n",
    "        bounds_y.append(cell.south_west.latitude)\n",
    "        bounds_y.append(cell.north_west.latitude)\n",
    "\n",
    "plt.scatter(\n",
    "    bounds_x,\n",
    "    bounds_y\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = 7 # Number of days to look back at\n",
    "F = 4 # Number of features per region per day\n",
    "G = 2 # Number of geografical features per region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Region centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from features.geographical.latitude import Latitude\n",
    "from features.geographical.longitude import Longitude\n",
    "\n",
    "region_centers = np.zeros(\n",
    "    shape=(\n",
    "        cells_width,\n",
    "        cells_height,\n",
    "        G\n",
    "    ),\n",
    "    dtype=np.float64\n",
    ")\n",
    "\n",
    "normalized_region_centers = np.zeros(\n",
    "    shape=(\n",
    "        cells_width,\n",
    "        cells_height,\n",
    "        G\n",
    "    ),\n",
    "    dtype=np.float64\n",
    ")\n",
    "\n",
    "normalized_x_for_plot = []\n",
    "normalized_y_for_plot = []\n",
    "x_for_plot = []\n",
    "y_for_plot = []\n",
    "for x in range(cells_width):\n",
    "    for y in range(cells_height):\n",
    "        region_centers[x, y, :] = cells[x][y].center.to_array()\n",
    "        normalized_region_centers[x][y][0] = Latitude.create_for(cells[x][y].center, whole_region_bbox).normalize()\n",
    "        normalized_region_centers[x][y][1] = Longitude.create_for(cells[x][y].center, whole_region_bbox).normalize()\n",
    "\n",
    "        normalized_x_for_plot.append(normalized_region_centers[x][y][1])\n",
    "        normalized_y_for_plot.append(normalized_region_centers[x][y][0])\n",
    "        x_for_plot.append(region_centers[x][y][1])\n",
    "        y_for_plot.append(region_centers[x][y][0])\n",
    "\n",
    "plt.scatter(normalized_x_for_plot, normalized_y_for_plot)\n",
    "plt.show()\n",
    "# plt.scatter(x_for_plot, y_for_plot)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal feature shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = Remote.get_date_range()\n",
    "dataset_size = (len(date_range) - N) * cells_width * cells_height\n",
    "\n",
    "first_input_features = np.zeros(\n",
    "    shape=(\n",
    "        dataset_size,\n",
    "        N,\n",
    "        F\n",
    "    ),\n",
    "    dtype=np.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical feature shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from remote.remote import Remote\n",
    "import numpy as np\n",
    "\n",
    "date_range = Remote.get_date_range()\n",
    "dataset_size = (len(date_range) - N) * cells_width * cells_height\n",
    "\n",
    "second_input_features = np.zeros(\n",
    "    shape=(\n",
    "        dataset_size,\n",
    "        2\n",
    "    ),\n",
    "    dtype=np.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from remote.remote import Remote\n",
    "import numpy as np\n",
    "\n",
    "date_range = Remote.get_date_range()\n",
    "dataset_size = (len(date_range) - N) * cells_width * cells_height\n",
    "\n",
    "outputs = np.zeros(\n",
    "    shape=(dataset_size),\n",
    "    dtype=np.float64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define last N days queue shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_queues = np.zeros(shape=(\n",
    "    cells_width,\n",
    "    cells_height,\n",
    "    len(date_range),\n",
    "    F\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-populate queue with first N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from features.factory import Factory\n",
    "\n",
    "# Iterate initial N dates to populate the queues\n",
    "for index, date in enumerate(date_range[:N]):\n",
    "\n",
    "    weather_features = Factory.get_weather_features(date)\n",
    "    risk_features, _ = Factory.get_risk_features(date, cells, whole_region_bbox, cells_width, cells_height, 2, DESIRED_REGION_SIZE_KM)\n",
    "\n",
    "    for xi in range(cells_width):\n",
    "        for yi in range(cells_height):\n",
    "            region_features = risk_features[xi][yi]\n",
    "\n",
    "            for z in range(len(region_features)):\n",
    "                region_queues[xi][yi][index][z] = region_features[z]\n",
    "\n",
    "            for z in range(len(weather_features)):\n",
    "                region_queues[xi][yi][index][z + len(region_features)] = weather_features[z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_index = 0\n",
    "queues_index = N\n",
    "accidents_per_day = []\n",
    "for date in date_range[N:]:\n",
    "\n",
    "    print(f'Processing date {date}', end='\\r')\n",
    "    weather_features = Factory.get_weather_features(date)\n",
    "    risk_features, total_acc = Factory.get_risk_features(date, cells, whole_region_bbox, cells_width, cells_height, 2, DESIRED_REGION_SIZE_KM)\n",
    "    accidents_per_day.append(total_acc)\n",
    "    for xi in range(cells_width):\n",
    "        for yi in range(cells_height):\n",
    "\n",
    "            region_features = risk_features[xi][yi]\n",
    "            expected_risk_index = risk_features[xi][yi][0]\n",
    "\n",
    "            first_input_features[global_index][:] = region_queues[xi][yi][-N:]\n",
    "            second_input_features[global_index][:] = normalized_region_centers[xi][yi]\n",
    "            outputs[global_index] = expected_risk_index\n",
    "\n",
    "            global_index += 1\n",
    "            for z in range(len(region_features)):\n",
    "                region_queues[xi][yi][queues_index][z] = region_features[z]\n",
    "\n",
    "            for z in range(len(weather_features)):\n",
    "                region_queues[xi][yi][queues_index][z + len(region_features)] = weather_features[z]\n",
    "            \n",
    "    queues_index += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Average accidents per day is {np.average(accidents_per_day)}')\n",
    "print(f'Max accidents per day is {np.max(accidents_per_day)}')\n",
    "print(f'Min accidents per day is {np.min(accidents_per_day)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Max index is {np.max(outputs)}')\n",
    "print(f'Min index is {np.min(outputs)}')\n",
    "print(f'Avg index is {np.average(outputs)}')\n",
    "print(f'Median index is {np.median(outputs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_leading_to_something = 0\n",
    "for i, feature_set in enumerate(first_input_features):\n",
    "    label = outputs[i]\n",
    "    has_non_zero = False\n",
    "    for j in range(7):\n",
    "        if (feature_set[j][0] != 0):\n",
    "            has_non_zero = True\n",
    "    if not has_non_zero and label != 0:\n",
    "        zeros_leading_to_something += 1\n",
    "print(f'A bunch of zero indices leading to a non-zero index happened {zeros_leading_to_something} times')\n",
    "print(f'For reference, the dataset is {len(first_input_features)} inputs big')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "FOLDER = \"data/\"\n",
    "INPUTS_1_FILE = FOLDER + \"inputs_1.pkl\"\n",
    "INPUTS_2_FILE = FOLDER + \"inputs_2.pkl\"\n",
    "OUTPUTS_FILE = FOLDER + \"outputs.pkl\"\n",
    "CENTERS_FILE = FOLDER + \"centers.pkl\"\n",
    "REGIONS_FILE = FOLDER + \"regions.pkl\"\n",
    "N_CENTERS_FILE = FOLDER + \"normal_centers.pkl\"\n",
    "SHAPE_FILE = FOLDER + \"shape.pkl\"\n",
    "\n",
    "if not os.path.exists(INPUTS_1_FILE):\n",
    "    with open(INPUTS_1_FILE, 'wb') as h:\n",
    "        pkl.dump(first_input_features, h)\n",
    "\n",
    "if not os.path.exists(INPUTS_2_FILE):\n",
    "    with open(INPUTS_2_FILE, 'wb') as h:\n",
    "        pkl.dump(second_input_features, h)\n",
    "\n",
    "if not os.path.exists(OUTPUTS_FILE):\n",
    "    with open(OUTPUTS_FILE, 'wb') as h:\n",
    "        pkl.dump(outputs, h)\n",
    "\n",
    "if not os.path.exists(CENTERS_FILE):\n",
    "    with open(CENTERS_FILE, 'wb') as h:\n",
    "        pkl.dump(region_centers, h)\n",
    "\n",
    "if not os.path.exists(N_CENTERS_FILE):\n",
    "    with open(N_CENTERS_FILE, 'wb') as h:\n",
    "        pkl.dump(normalized_region_centers, h)\n",
    "\n",
    "if not os.path.exists(REGIONS_FILE):\n",
    "    with open(REGIONS_FILE, 'wb') as h:\n",
    "        pkl.dump(cells, h)\n",
    "\n",
    "if not os.path.exists(SHAPE_FILE):\n",
    "    with open(SHAPE_FILE, 'wb') as h:\n",
    "        pkl.dump([cells_width, cells_height, G, N, F, dataset_size], h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('tf-downgrade')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c317347876957d0732c2360af00ee06efb91188ffda278c05bb97c75a0b68f32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
